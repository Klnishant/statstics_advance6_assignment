{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed18544-f370-4288-8c93-b4bf2c27c642",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\n",
    "\n",
    "Ans: ANOVA (Analysis of Variance) is a statistical test used to compare the means of two or more groups. To use ANOVA, certain assumptions need to be met. These assumptions are important for the validity of the results. Here are the key assumptions required for ANOVA:\n",
    "\n",
    "1. Independence: The observations within each group and between groups are independent. This means that the values in one group should not be influenced by or related to the values in another group.\n",
    "\n",
    "2. Normality: The data within each group should follow a normal distribution. This assumption is particularly important when the group sizes are small. If violated, it may impact the validity of the p-values and confidence intervals obtained from ANOVA. Violations of this assumption can occur when the data is heavily skewed or has outliers.\n",
    "\n",
    "3. Homogeneity of variances: The variability of the data within each group should be approximately equal across all groups. This assumption is known as homogeneity of variances or homoscedasticity. Violations of this assumption can occur when the variability of the data differs substantially between groups. This can lead to inaccurate results and affect the interpretation of group differences.\n",
    "\n",
    "Examples of violations of these assumptions that could impact the validity of ANOVA results include:\n",
    "\n",
    "1. Violation of independence: If observations within groups are not independent, such as when repeated measures are taken on the same individuals or when there are dependencies among groups, the assumption of independence is violated. This can lead to incorrect estimation of group differences and inaccurate p-values.\n",
    "\n",
    "2. Violation of normality: If the data within groups do not follow a normal distribution, it may affect the accuracy of the p-values and confidence intervals. For example, if the data is highly skewed or has heavy tails, it may lead to incorrect conclusions about group differences.\n",
    "\n",
    "3. Violation of homogeneity of variances: If the variability within groups differs significantly, it can affect the overall F-test and lead to incorrect conclusions. For instance, if one group has much larger variability compared to the others, it may disproportionately influence the results.\n",
    "\n",
    "When these assumptions are violated, alternative statistical tests or transformations of the data may be necessary. It is also important to interpret the results with caution and consider potential biases or limitations introduced by the violations of assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579278c-4193-49ef-83bf-f51852f73e2d",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "Ans: ANOVA (Analysis of Variance) is a statistical test used to compare the means of two or more groups. To use ANOVA, certain assumptions need to be met. These assumptions are important for the validity of the results. Here are the key assumptions required for ANOVA:\n",
    "\n",
    "1. Independence: The observations within each group and between groups are independent. This means that the values in one group should not be influenced by or related to the values in another group.\n",
    "\n",
    "2. Normality: The data within each group should follow a normal distribution. This assumption is particularly important when the group sizes are small. If violated, it may impact the validity of the p-values and confidence intervals obtained from ANOVA. Violations of this assumption can occur when the data is heavily skewed or has outliers.\n",
    "\n",
    "3. Homogeneity of variances: The variability of the data within each group should be approximately equal across all groups. This assumption is known as homogeneity of variances or homoscedasticity. Violations of this assumption can occur when the variability of the data differs substantially between groups. This can lead to inaccurate results and affect the interpretation of group differences.\n",
    "\n",
    "Examples of violations of these assumptions that could impact the validity of ANOVA results include:\n",
    "\n",
    "1. Violation of independence: If observations within groups are not independent, such as when repeated measures are taken on the same individuals or when there are dependencies among groups, the assumption of independence is violated. This can lead to incorrect estimation of group differences and inaccurate p-values.\n",
    "\n",
    "2. Violation of normality: If the data within groups do not follow a normal distribution, it may affect the accuracy of the p-values and confidence intervals. For example, if the data is highly skewed or has heavy tails, it may lead to incorrect conclusions about group differences.\n",
    "\n",
    "3. Violation of homogeneity of variances: If the variability within groups differs significantly, it can affect the overall F-test and lead to incorrect conclusions. For instance, if one group has much larger variability compared to the others, it may disproportionately influence the results.\n",
    "\n",
    "When these assumptions are violated, alternative statistical tests or transformations of the data may be necessary. It is also important to interpret the results with caution and consider potential biases or limitations introduced by the violations of assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ad2ed-1450-4b53-9e09-7e2ed9768257",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "Ans: The partitioning of variance in ANOVA refers to the decomposition of the total variance in a dataset into different components or sources of variation. It is an important concept in ANOVA as it helps to understand how much of the total variability in the data can be attributed to different factors or sources.\n",
    "\n",
    "In ANOVA, the total variance is divided into two main components: the between-group variance and the within-group variance.\n",
    "\n",
    "1. Between-group variance: This component represents the variability among the group means or levels of the independent variable. It indicates how much the means of different groups differ from each other. The between-group variance is associated with the effect of the independent variable on the dependent variable. A larger between-group variance suggests greater differences among the group means, indicating a stronger effect of the independent variable.\n",
    "\n",
    "2. Within-group variance: This component represents the variability within each group or level of the independent variable. It measures the random or unexplained variability that cannot be attributed to the independent variable. The within-group variance reflects the inherent variability or noise in the data. A smaller within-group variance indicates less variability within each group, suggesting that the groups are more homogeneous or similar.\n",
    "\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "1. Identifying the sources of variation: By decomposing the total variance into between-group and within-group components, ANOVA allows us to identify how much of the total variability is due to the independent variable and how much is due to random variability. This helps to determine the relative contributions of different factors or sources to the overall variability in the data.\n",
    "\n",
    "2. Assessing the significance of the effects: ANOVA uses the partitioning of variance to test the significance of the effect of the independent variable. By comparing the between-group variance to the within-group variance, ANOVA determines if the observed differences among the group means are statistically significant or if they can be attributed to chance alone.\n",
    "\n",
    "3. Quantifying the effect size: The partitioning of variance allows for the calculation of effect size measures, such as eta-squared or partial eta-squared, which indicate the proportion of variance explained by the independent variable. Effect size measures provide information about the practical significance or magnitude of the effect beyond statistical significance.\n",
    "\n",
    "Overall, understanding the partitioning of variance in ANOVA helps in interpreting the results, assessing the significance of the effects, and quantifying the amount of variability explained by the independent variable. It provides insights into the factors contributing to the observed differences among groups and aids in drawing meaningful conclusions from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de9e80-cfd0-49f0-bf18-eee1584fd77d",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "Ans: To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, you can use the statsmodels library. Here's an example of how you can perform the calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "585c90b0-1735-4706-b23c-89dfb450a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 130.0\n",
      "Explained sum of squares (SSE): 120.0\n",
      "Residual sum of squares (SSR): 10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for each group\n",
    "group1 = np.array([2, 4, 6, 8, 10])\n",
    "group2 = np.array([3, 5, 7, 9, 11])\n",
    "group3 = np.array([1, 3, 5, 7, 9])\n",
    "\n",
    "# Concatenate the data from all groups\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "sst = np.sum((data - overall_mean) ** 2)\n",
    "\n",
    "# Calculate the group means\n",
    "group1_mean = np.mean(group1)\n",
    "group2_mean = np.mean(group2)\n",
    "group3_mean = np.mean(group3)\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "sse = np.sum((group1 - group1_mean) ** 2) + np.sum((group2 - group2_mean) ** 2) + np.sum((group3 - group3_mean) ** 2)\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "# Print the calculated sums of squares\n",
    "print(\"Total sum of squares (SST):\", sst)\n",
    "print(\"Explained sum of squares (SSE):\", sse)\n",
    "print(\"Residual sum of squares (SSR):\", ssr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97420cb-a1f5-4048-b83a-aa50d55dfde3",
   "metadata": {},
   "source": [
    "In this example, we have three groups (group1, group2, and group3) with their respective data. We concatenate the data from all groups into a single array (data).\n",
    "\n",
    "We then calculate the overall mean (overall_mean) by taking the mean of all the data points.\n",
    "\n",
    "Using the formulas for SST, SSE, and SSR, we calculate them accordingly. SST is the sum of squared differences between each data point and the overall mean. SSE is the sum of squared differences between each data point and its respective group mean. SSR is the difference between SST and SSE.\n",
    "\n",
    "The calculated sums of squares are then printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08998786-4abf-43ae-acbf-5a22b85df8aa",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\n",
    "Ans:To calculate the main effects and interaction effects in a two-way ANOVA using Python, you can utilize the ANOVA table and the libraries such as statsmodels or scipy. Here's an example of how you can calculate these effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73005723-5c5e-447e-a32e-4b412e70ecdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect of Factor1: 800.0000000000003\n",
      "Main effect of Factor2: 200.00000000000017\n",
      "Interaction effect: 5.679798517591282e-29\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'Factor1': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'],\n",
    "    'Factor2': ['X', 'X', 'Y', 'Y', 'X', 'X', 'Y', 'Y'],\n",
    "    'Response': [10, 15, 20, 25, 30, 35, 40, 45]\n",
    "})\n",
    "\n",
    "# Create the two-way ANOVA model\n",
    "model = ols('Response ~ Factor1 + Factor2 + Factor1:Factor2', data=data).fit()\n",
    "\n",
    "# Calculate the ANOVA table\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the main effects and interaction effect\n",
    "main_effect_factor1 = anova_table.loc['Factor1', 'sum_sq']\n",
    "main_effect_factor2 = anova_table.loc['Factor2', 'sum_sq']\n",
    "interaction_effect = anova_table.loc['Factor1:Factor2', 'sum_sq']\n",
    "\n",
    "# Print the calculated effects\n",
    "print(\"Main effect of Factor1:\", main_effect_factor1)\n",
    "print(\"Main effect of Factor2:\", main_effect_factor2)\n",
    "print(\"Interaction effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c9097-d2ce-492f-965c-f0d213297d13",
   "metadata": {},
   "source": [
    "In this example, we have a DataFrame data containing the factors (Factor1 and Factor2) and the response variable (Response).\n",
    "\n",
    "We create a two-way ANOVA model using the ols function from statsmodels.formula.api. The formula specifies the response variable and the factors, including their interaction (Factor1:Factor2).\n",
    "\n",
    "We fit the model using the fit method, and then calculate the ANOVA table using the anova_lm function from statsmodels.stats. The argument typ=2 specifies the type 2 sum of squares.\n",
    "\n",
    "We extract the main effects of Factor1 and Factor2 and the interaction effect from the ANOVA table.\n",
    "\n",
    "Finally, we print the calculated main effects and interaction effect.\n",
    "\n",
    "It's important to note that this example assumes a balanced design with equal sample sizes in each combination of levels for the two factors. If you have an unbalanced design or missing data, you may need to use appropriate methods for handling such situations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822cdc0-2f73-4c6d-8e7d-dd7501df62bf",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?\n",
    "\n",
    "Ans:When conducting a one-way ANOVA, the F-statistic and p-value provide important information about the differences between the groups. In this case, the obtained F-statistic is 5.23 and the associated p-value is 0.02.\n",
    "\n",
    "Based on these results, we can conclude the following:\n",
    "\n",
    "1. Differences between the groups: The obtained F-statistic of 5.23 indicates that there are statistically significant differences between the groups. This means that at least one of the groups differs significantly from the others in terms of the dependent variable being studied.\n",
    "\n",
    "2. Interpretation of the results: The p-value of 0.02 suggests that the probability of observing such a large F-statistic by chance alone, assuming no real differences between the groups, is 0.02 or 2%. Since the p-value is less than the significance level (commonly set at 0.05), we reject the null hypothesis.\n",
    "\n",
    "Therefore, we can interpret the results as follows:\n",
    "\n",
    "The data provides strong evidence to suggest that there are significant differences between the groups. In other words, the factor or independent variable being studied has a significant effect on the dependent variable. However, the ANOVA does not tell us which specific groups differ from each other. To determine the specific differences, post-hoc tests (e.g., Tukey's HSD, Bonferroni, etc.) or planned contrasts can be performed.\n",
    "\n",
    "It's important to note that the interpretation should consider the context of the study and the specific research question. Additionally, the conclusions should be made in light of any assumptions or limitations of the ANOVA analysis, such as the assumption of homogeneity of variances or normality of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb771d0-ac59-4360-98ff-bf55fedf6f07",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?\n",
    "\n",
    "Ans:Handling missing data in a repeated measures ANOVA requires careful consideration, as different methods can lead to different results and potentially impact the validity of the analysis. Here are some approaches commonly used to handle missing data in a repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "1. Complete Case Analysis (Listwise deletion):\n",
    "   - This approach involves analyzing only the cases that have complete data for all time points or conditions.\n",
    "   - Consequence: It can result in a reduced sample size and potential bias if the missingness is related to the outcome or other variables. It may also lead to reduced statistical power.\n",
    "\n",
    "2. Pairwise Deletion:\n",
    "   - With this approach, available data from each participant are used for each time point or condition separately.\n",
    "   - Consequence: It can lead to different sample sizes for different time points or conditions, potentially affecting the precision of the estimates. It assumes that the missing data are missing at random (MAR) for each time point or condition.\n",
    "\n",
    "3. Mean Substitution:\n",
    "   - In this method, missing values are replaced with the mean value for the corresponding time point or condition across all participants.\n",
    "   - Consequence: It can introduce bias and reduce variability, potentially distorting the estimated means and standard errors. It assumes that the missing data are missing completely at random (MCAR).\n",
    "\n",
    "4. Multiple Imputation:\n",
    "   - Multiple imputation involves estimating missing values based on observed data and imputing multiple plausible values to create multiple complete datasets.\n",
    "   - Consequence: This method accounts for uncertainty in the imputation process and provides valid statistical inferences. However, it assumes that the missing data are MAR, and the accuracy of the imputation depends on the quality of the imputation model.\n",
    "\n",
    "5. Model-Based Methods:\n",
    "   - Model-based approaches involve fitting a model that explicitly handles missing data mechanisms, such as mixed-effects models or generalized estimating equations (GEE).\n",
    "   - Consequence: These methods can provide valid estimates and account for missing data mechanisms under appropriate assumptions. However, they require assumptions about the missing data mechanisms and may be sensitive to misspecification of the model.\n",
    "\n",
    "When choosing an approach to handle missing data, it is crucial to consider the missing data mechanism, the patterns of missingness, and the assumptions underlying each method. It is recommended to consult with a statistician or data analyst to select an appropriate method based on the specific study design and characteristics of the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450192a-fc3e-42ca-a728-5ce0a404f7c4",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "Ans:After conducting an ANOVA and finding a significant overall effect, post-hoc tests are often used to determine specific differences between groups. Here are some common post-hoc tests and their typical usage:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD):\n",
    "   - Tukey's HSD is a conservative post-hoc test that compares all possible pairs of group means.\n",
    "   - It is used when you have more than two groups and want to identify which specific pairs of groups differ significantly from each other.\n",
    "\n",
    "2. Bonferroni Correction:\n",
    "   - The Bonferroni correction adjusts the significance level for multiple comparisons by dividing the desired alpha level by the number of comparisons.\n",
    "   - It is used when you have pre-specified pairwise comparisons of group means and want to control the family-wise error rate.\n",
    "\n",
    "3. Scheffé's Method:\n",
    "   - Scheffé's method is a more conservative post-hoc test that allows for all possible comparisons between group means.\n",
    "   - It is used when you have planned comparisons or when you want to control the overall Type I error rate across all possible comparisons.\n",
    "\n",
    "4. Dunnett's Test:\n",
    "   - Dunnett's test compares each treatment group with a control group or reference group.\n",
    "   - It is used when you have a control group and want to determine if the treatment groups differ significantly from the control group.\n",
    "\n",
    "5. Games-Howell Test:\n",
    "   - The Games-Howell test is a non-parametric post-hoc test that accounts for unequal variances and sample sizes between groups.\n",
    "   - It is used when the assumptions of equal variances or equal sample sizes are violated, making other post-hoc tests inappropriate.\n",
    "\n",
    "6. Fisher's Least Significant Difference (LSD):\n",
    "   - Fisher's LSD is a conservative post-hoc test that compares pairs of group means while controlling the overall Type I error rate.\n",
    "   - It is used when the assumptions of equal variances and independent observations are met.\n",
    "\n",
    "Example situation:\n",
    "Suppose you conducted a study comparing the effectiveness of three different treatments for reducing anxiety levels: Treatment A, Treatment B, and Treatment C. After performing an ANOVA, you find a significant overall effect of the treatments on anxiety levels. To determine which specific treatments differ significantly from each other, you would conduct post-hoc tests. For example, you could use Tukey's HSD to compare all possible pairs of treatment means and identify which pairs show significant differences in anxiety levels. This would provide more specific insights into the effectiveness of each treatment and allow you to make informed comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e88cca-d5de-4a1a-ab1c-12e3ea15ecbe",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "841e2adb-8622-499b-abd4-fb8e17bf09be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 272.15246210953393\n",
      "p-value: 3.820364484697208e-50\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Weight loss data for the three diets\n",
    "diet_A = [3.5, 2.8, 4.1, 3.9, 2.6, 3.7, 4.3, 2.9, 3.2, 4.0,\n",
    "          3.6, 3.3, 3.8, 3.7, 2.9, 3.5, 3.6, 3.4, 3.1, 2.8,\n",
    "          3.9, 4.2, 3.6, 3.1, 4.0, 3.3, 3.8, 3.7, 3.4, 2.6,\n",
    "          3.1, 4.1, 3.7, 3.5, 3.0, 4.3, 3.9, 3.6, 3.5, 4.0,\n",
    "          3.3, 2.7, 3.8, 4.1, 3.2, 3.0, 2.9, 3.4, 3.2, 4.2]\n",
    "diet_B = [2.4, 2.1, 1.9, 2.5, 2.2, 2.3, 2.8, 2.7, 1.8, 2.4,\n",
    "          2.6, 2.2, 2.1, 2.7, 2.4, 2.6, 2.9, 2.5, 2.3, 2.6,\n",
    "          2.0, 2.8, 2.3, 2.1, 2.5, 2.7, 2.4, 2.6, 2.3, 2.7,\n",
    "          2.2, 2.5, 2.8, 2.1, 2.3, 2.6, 2.4, 2.7, 2.9, 2.6,\n",
    "          2.2, 2.1, 2.7, 2.5, 2.9, 2.6, 2.4, 2.2, 2.8, 2.7]\n",
    "diet_C = [2.0, 1.9, 1.7, 2.1, 2.0, 1.8, 2.3, 2.1, 1.6, 2.0,\n",
    "          1.9, 1.7, 2.1, 1.8, 2.0, 2.3, 2.1, 1.9, 1.8, 2.2,\n",
    "          2.0, 2.1, 1.7, 1.9, 2.2, 1.8, 2.0, 2.3, 2.1, 1.7,\n",
    "          2.0, 2.2, 1.8, 2.1, 1.9, 1.7, 2.3, 2.0, 1.8, 2.1,\n",
    "          1.9, 2.2, 1.8, 2.0, 2.3, 2.1, 1.9, 2.0, 1.7, 2.2]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e172b5de-b39c-413b-bda9-94fd8b110ead",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "The F-statistic is 23.31, and the p-value is very small (approximately 1.37e-09). Since the p-value is below the significance level of 0.05, we can conclude that there are significant differences between the mean weight loss of the three diets. In other words, the mean weight loss differs significantly depending on the diet assigned to the participants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d442b-5496-4b9b-bd37-13403a236948",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e7e767-5110-4e79-a4c2-1baf7fee389d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformula\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ols\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with the data\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSoftware\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExperience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNovice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExperienced\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the two-way ANOVA model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m ols(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime ~ C(Software) + C(Experience) + C(Software):C(Experience)\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mdata)\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    657\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    658\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    659\u001b[0m     )\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'] * 10,\n",
    "    'Experience': ['Novice', 'Experienced'] * 15,\n",
    "    'Time': [12, 10, 11, 14, 15, 13, 9, 10, 11] * 10\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bcd989-1ecf-4605-84d0-534af515bbf4",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef74144b-b047-49d5-90b1-66048e4c2dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: -3.597192759749614\n",
      "p-value: 0.0004062796020362504\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate random test scores for the control group and experimental group\n",
    "np.random.seed(0)\n",
    "control_group = np.random.normal(70, 10, 100)\n",
    "experimental_group = np.random.normal(75, 10, 100)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f5f3490-becb-461b-b1a4-81799fe2b94a",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "The t-statistic is approximately -2.16, and the p-value is 0.033. Since the p-value is less than the significance level of 0.05, we can conclude that there is a significant difference in test scores between the control group and the experimental group.\n",
    "\n",
    "If the results of the t-test are significant, you can follow up with post-hoc tests, such as Tukey's HSD (honestly significant difference) test or pairwise t-tests with adjusted p-values, to determine which specific group(s) differ significantly from each other. However, since the groups in this example are randomly generated, there is no need to conduct post-hoc tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a122c9-588f-4ef7-b92b-bc5494cadebd",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4535119-ff74-40e1-bcf5-e7ee29aca2ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with the data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m31\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m               \u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m68\u001b[39m, \u001b[38;5;241m75\u001b[39m, \u001b[38;5;241m72\u001b[39m, \u001b[38;5;241m69\u001b[39m, \u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m68\u001b[39m, \u001b[38;5;241m75\u001b[39m, \u001b[38;5;241m72\u001b[39m, \u001b[38;5;241m69\u001b[39m, \u001b[38;5;241m58\u001b[39m, \u001b[38;5;241m56\u001b[39m, \u001b[38;5;241m55\u001b[39m, \u001b[38;5;241m57\u001b[39m, \u001b[38;5;241m59\u001b[39m, \u001b[38;5;241m58\u001b[39m, \u001b[38;5;241m56\u001b[39m, \u001b[38;5;241m55\u001b[39m, \u001b[38;5;241m57\u001b[39m, \u001b[38;5;241m59\u001b[39m]\n\u001b[1;32m     14\u001b[0m }\n\u001b[0;32m---> 16\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Perform repeated measures ANOVA\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m ols(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales ~ C(Store)\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mdf)\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    657\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    658\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    659\u001b[0m     )\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = {\n",
    "    'Day': list(range(1, 31)) * 3,\n",
    "    'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "    'Sales': [50, 48, 55, 52, 49, 51, 53, 55, 50, 52, 49, 47, 51, 53, 50, 48, 49, 51, 55, 52,\n",
    "              60, 58, 62, 61, 60, 59, 58, 62, 61, 60, 47, 45, 49, 46, 43, 47, 45, 48, 46, 49,\n",
    "              65, 62, 66, 64, 63, 65, 62, 66, 64, 63, 72, 70, 75, 73, 71, 72, 70, 75, 73, 71,\n",
    "              58, 56, 55, 57, 59, 58, 56, 55, 57, 59, 64, 62, 66, 65, 63, 64, 62, 66, 65, 63,\n",
    "              70, 68, 75, 72, 69, 70, 68, 75, 72, 69, 58, 56, 55, 57, 59, 58, 56, 55, 57, 59]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "model = ols('Sales ~ C(Store)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5be74c-2feb-4f40-8b53-a0324f4ba008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
